{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "from kerashypetune import KerasGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6036, 28, 28), (6036,), (2963, 28, 28), (2963,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "np.random.seed(33)\n",
    "subset_train = np.random.uniform(0,1, len(y_train))\n",
    "subset_test = np.random.uniform(0,1, len(y_test))\n",
    "\n",
    "x_train = x_train[subset_train < 0.1] / 255\n",
    "y_train = y_train[subset_train < 0.1]\n",
    "\n",
    "x_test = x_test[subset_test < 0.3] / 255\n",
    "y_test = y_test[subset_test < 0.3]\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(param):\n",
    "    \n",
    "    set_seed(33)\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(param['unit_1'], activation='relu'))\n",
    "    \n",
    "    if param['cond']:\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=param['lr']), \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'unit_1': [128,64], \n",
    "    'lr': [1e-2,1e-3], \n",
    "    'cond': [True,False],\n",
    "    'epochs': 100, \n",
    "    'batch_size': 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8 trials detected for ('unit_1', 'lr', 'cond', 'epochs', 'batch_size')\n",
      "\n",
      "***** (1/8) *****\n",
      "Search({'unit_1': 128, 'lr': 0.01, 'cond': False, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "SCORE: 0.95444 at epoch 15\n",
      "\n",
      "***** (2/8) *****\n",
      "Search({'unit_1': 128, 'lr': 0.01, 'cond': True, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "SCORE: 0.9568 at epoch 18\n",
      "\n",
      "***** (3/8) *****\n",
      "Search({'unit_1': 128, 'lr': 0.001, 'cond': False, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00042: early stopping\n",
      "SCORE: 0.94263 at epoch 32\n",
      "\n",
      "***** (4/8) *****\n",
      "Search({'unit_1': 128, 'lr': 0.001, 'cond': True, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n",
      "SCORE: 0.95039 at epoch 27\n",
      "\n",
      "***** (5/8) *****\n",
      "Search({'unit_1': 64, 'lr': 0.01, 'cond': False, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "SCORE: 0.95073 at epoch 22\n",
      "\n",
      "***** (6/8) *****\n",
      "Search({'unit_1': 64, 'lr': 0.01, 'cond': True, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "SCORE: 0.94803 at epoch 12\n",
      "\n",
      "***** (7/8) *****\n",
      "Search({'unit_1': 64, 'lr': 0.001, 'cond': False, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00042: early stopping\n",
      "SCORE: 0.93891 at epoch 40\n",
      "\n",
      "***** (8/8) *****\n",
      "Search({'unit_1': 64, 'lr': 0.001, 'cond': True, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00041: early stopping\n",
      "SCORE: 0.94431 at epoch 31\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=10, verbose=1, min_delta=0.001, monitor='val_accuracy', mode='auto', restore_best_weights=True)\n",
    "\n",
    "hypermodel = get_model\n",
    "\n",
    "kgs = KerasGridSearch(hypermodel, param_grid, monitor='val_accuracy', greater_is_better=True, tuner_verbose=1)\n",
    "kgs.search(x_train, y_train, validation_data=(x_test, y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable number of layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(param):\n",
    "    \n",
    "    set_seed(33)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(param['unit_1'], activation='relu'))\n",
    "    \n",
    "    for n in range(param['n_layer'],0,-1):\n",
    "        model.add(Dense(16*n, activation='relu'))\n",
    "        \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=param['lr']), \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'unit_1': [128,64], \n",
    "    'lr': [1e-2,1e-3], \n",
    "    'n_layer': [4,3],\n",
    "    'epochs': 100, \n",
    "    'batch_size': 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8 trials detected for ('unit_1', 'lr', 'n_layer', 'epochs', 'batch_size')\n",
      "\n",
      "***** (1/8) *****\n",
      "Search({'unit_1': 128, 'lr': 0.01, 'n_layer': 3, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "SCORE: 0.94668 at epoch 14\n",
      "\n",
      "***** (2/8) *****\n",
      "Search({'unit_1': 128, 'lr': 0.01, 'n_layer': 4, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "SCORE: 0.95478 at epoch 14\n",
      "\n",
      "***** (3/8) *****\n",
      "Search({'unit_1': 128, 'lr': 0.001, 'n_layer': 3, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "SCORE: 0.94803 at epoch 30\n",
      "\n",
      "***** (4/8) *****\n",
      "Search({'unit_1': 128, 'lr': 0.001, 'n_layer': 4, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00036: early stopping\n",
      "SCORE: 0.9514 at epoch 26\n",
      "\n",
      "***** (5/8) *****\n",
      "Search({'unit_1': 64, 'lr': 0.01, 'n_layer': 3, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "SCORE: 0.94296 at epoch 12\n",
      "\n",
      "***** (6/8) *****\n",
      "Search({'unit_1': 64, 'lr': 0.01, 'n_layer': 4, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n",
      "SCORE: 0.94634 at epoch 24\n",
      "\n",
      "***** (7/8) *****\n",
      "Search({'unit_1': 64, 'lr': 0.001, 'n_layer': 3, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00041: early stopping\n",
      "SCORE: 0.93858 at epoch 31\n",
      "\n",
      "***** (8/8) *****\n",
      "Search({'unit_1': 64, 'lr': 0.001, 'n_layer': 4, 'epochs': 100, 'batch_size': 256})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "SCORE: 0.9406 at epoch 36\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=10, verbose=1, min_delta=0.001, monitor='val_accuracy', mode='auto', restore_best_weights=True)\n",
    "\n",
    "hypermodel = get_model\n",
    "\n",
    "kgs = KerasGridSearch(hypermodel, param_grid, monitor='val_accuracy', greater_is_better=True, tuner_verbose=1)\n",
    "kgs.search(x_train, y_train, validation_data=(x_test, y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional layer choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(param):\n",
    "    \n",
    "    set_seed(33)\n",
    "    \n",
    "    layer_choices = {'flat': Flatten(),\n",
    "                     'pool': GlobalMaxPool2D()}\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: tf.expand_dims(x,-1))) # add a dim for conv2d\n",
    "    model.add(Conv2D(param['unit'], param['kernel'], activation='relu'))\n",
    "    model.add(layer_choices[param['layer_types']])\n",
    "            \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=param['lr']), \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'unit': [32,64], \n",
    "    'kernel' : 3,\n",
    "    'lr': [1e-2,1e-1], \n",
    "    'layer_types': ['pool','flat'],\n",
    "    'epochs': 100, \n",
    "    'batch_size': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8 trials detected for ('unit', 'kernel', 'lr', 'layer_types', 'epochs', 'batch_size')\n",
      "\n",
      "***** (1/8) *****\n",
      "Search({'unit': 32, 'kernel': 3, 'lr': 0.1, 'layer_types': 'flat', 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "SCORE: 0.92913 at epoch 18\n",
      "\n",
      "***** (2/8) *****\n",
      "Search({'unit': 32, 'kernel': 3, 'lr': 0.1, 'layer_types': 'pool', 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "SCORE: 0.108 at epoch 3\n",
      "\n",
      "***** (3/8) *****\n",
      "Search({'unit': 32, 'kernel': 3, 'lr': 0.01, 'layer_types': 'flat', 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "SCORE: 0.96423 at epoch 13\n",
      "\n",
      "***** (4/8) *****\n",
      "Search({'unit': 32, 'kernel': 3, 'lr': 0.01, 'layer_types': 'pool', 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00040: early stopping\n",
      "SCORE: 0.71785 at epoch 35\n",
      "\n",
      "***** (5/8) *****\n",
      "Search({'unit': 64, 'kernel': 3, 'lr': 0.1, 'layer_types': 'flat', 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "SCORE: 0.8866 at epoch 9\n",
      "\n",
      "***** (6/8) *****\n",
      "Search({'unit': 64, 'kernel': 3, 'lr': 0.1, 'layer_types': 'pool', 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "SCORE: 0.1134 at epoch 1\n",
      "\n",
      "***** (7/8) *****\n",
      "Search({'unit': 64, 'kernel': 3, 'lr': 0.01, 'layer_types': 'flat', 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "SCORE: 0.96625 at epoch 8\n",
      "\n",
      "***** (8/8) *****\n",
      "Search({'unit': 64, 'kernel': 3, 'lr': 0.01, 'layer_types': 'pool', 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00054: early stopping\n",
      "SCORE: 0.77354 at epoch 49\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=5, verbose=1, min_delta=0.001, monitor='val_accuracy', mode='auto', restore_best_weights=True)\n",
    "\n",
    "hypermodel = get_model\n",
    "\n",
    "kgs = KerasGridSearch(hypermodel, param_grid, monitor='val_accuracy', greater_is_better=True, tuner_verbose=1)\n",
    "kgs.search(x_train, y_train, validation_data=(x_test, y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(param):\n",
    "    \n",
    "    set_seed(33)\n",
    "    \n",
    "    opt_choices = {'adam': Adam(),\n",
    "                   'nadam': Nadam()}\n",
    "    \n",
    "    opt = opt_choices[param['opt']]\n",
    "    opt.lr = param['lr'] \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(param['unit_1'], activation='relu'))\n",
    "    model.add(Dense(param['unit_2'], activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'unit_1': [128,64], \n",
    "    'unit_2': [64,32],\n",
    "    'opt': ['adam','nadam'],\n",
    "    'lr': [1e-2,1e-3], \n",
    "    'epochs': 100, \n",
    "    'batch_size': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 trials detected for ('unit_1', 'unit_2', 'opt', 'lr', 'epochs', 'batch_size')\n",
      "\n",
      "***** (1/16) *****\n",
      "Search({'unit_1': 128, 'unit_2': 64, 'opt': 'adam', 'lr': 0.01, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "SCORE: 0.95174 at epoch 13\n",
      "\n",
      "***** (2/16) *****\n",
      "Search({'unit_1': 128, 'unit_2': 64, 'opt': 'adam', 'lr': 0.001, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "SCORE: 0.95005 at epoch 28\n",
      "\n",
      "***** (3/16) *****\n",
      "Search({'unit_1': 128, 'unit_2': 64, 'opt': 'nadam', 'lr': 0.01, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "SCORE: 0.95073 at epoch 7\n",
      "\n",
      "***** (4/16) *****\n",
      "Search({'unit_1': 128, 'unit_2': 64, 'opt': 'nadam', 'lr': 0.001, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n",
      "SCORE: 0.94938 at epoch 30\n",
      "\n",
      "***** (5/16) *****\n",
      "Search({'unit_1': 128, 'unit_2': 32, 'opt': 'adam', 'lr': 0.01, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "SCORE: 0.9514 at epoch 14\n",
      "\n",
      "***** (6/16) *****\n",
      "Search({'unit_1': 128, 'unit_2': 32, 'opt': 'adam', 'lr': 0.001, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00029: early stopping\n",
      "SCORE: 0.94533 at epoch 24\n",
      "\n",
      "***** (7/16) *****\n",
      "Search({'unit_1': 128, 'unit_2': 32, 'opt': 'nadam', 'lr': 0.01, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "SCORE: 0.94668 at epoch 10\n",
      "\n",
      "***** (8/16) *****\n",
      "Search({'unit_1': 128, 'unit_2': 32, 'opt': 'nadam', 'lr': 0.001, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "SCORE: 0.94398 at epoch 22\n",
      "\n",
      "***** (9/16) *****\n",
      "Search({'unit_1': 64, 'unit_2': 64, 'opt': 'adam', 'lr': 0.01, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "SCORE: 0.95073 at epoch 14\n",
      "\n",
      "***** (10/16) *****\n",
      "Search({'unit_1': 64, 'unit_2': 64, 'opt': 'adam', 'lr': 0.001, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00029: early stopping\n",
      "SCORE: 0.93824 at epoch 28\n",
      "\n",
      "***** (11/16) *****\n",
      "Search({'unit_1': 64, 'unit_2': 64, 'opt': 'nadam', 'lr': 0.01, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "SCORE: 0.94701 at epoch 17\n",
      "\n",
      "***** (12/16) *****\n",
      "Search({'unit_1': 64, 'unit_2': 64, 'opt': 'nadam', 'lr': 0.001, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n",
      "SCORE: 0.9406 at epoch 34\n",
      "\n",
      "***** (13/16) *****\n",
      "Search({'unit_1': 64, 'unit_2': 32, 'opt': 'adam', 'lr': 0.01, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "SCORE: 0.9487 at epoch 18\n",
      "\n",
      "***** (14/16) *****\n",
      "Search({'unit_1': 64, 'unit_2': 32, 'opt': 'adam', 'lr': 0.001, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00042: early stopping\n",
      "SCORE: 0.93925 at epoch 37\n",
      "\n",
      "***** (15/16) *****\n",
      "Search({'unit_1': 64, 'unit_2': 32, 'opt': 'nadam', 'lr': 0.01, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "SCORE: 0.94735 at epoch 12\n",
      "\n",
      "***** (16/16) *****\n",
      "Search({'unit_1': 64, 'unit_2': 32, 'opt': 'nadam', 'lr': 0.001, 'epochs': 100, 'batch_size': 512})\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "SCORE: 0.93486 at epoch 22\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=5, verbose=1, min_delta=0.001, monitor='val_accuracy', mode='auto', restore_best_weights=True)\n",
    "\n",
    "hypermodel = get_model\n",
    "\n",
    "kgs = KerasGridSearch(hypermodel, param_grid, monitor='val_accuracy', greater_is_better=True, tuner_verbose=1)\n",
    "kgs.search(x_train, y_train, validation_data=(x_test, y_test), callbacks=[es])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
